{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\zyth0001\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zyth0001\\Anaconda3\\envs\\dialog-classification\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from polyjuice import Polyjuice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zyth0001\\Anaconda3\\envs\\dialog-classification\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:polyjuice.polyjuice_wrapper:Setup Polyjuice.\n",
      "INFO:polyjuice.polyjuice_wrapper:Setup SpaCy processor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: {'generated_token_ids': [1026, 318, 1049, 329, 3988, 13, 1279, 91, 11766, 5945, 91, 29, 685, 2588, 605, 60, 685, 9148, 15154, 60, 632, 318, 1049, 329, 3988, 13, 685, 5188, 47, 60, 38144, 9936, 685, 15037, 45532, 60, 220, 50256]}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\GIT\\Merlot\\dialog-classification\\counterfactuals.ipynb Zelle 3\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GIT/Merlot/dialog-classification/counterfactuals.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pj \u001b[39m=\u001b[39m Polyjuice(model_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muw-hai/polyjuice\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GIT/Merlot/dialog-classification/counterfactuals.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mIt is great for kids.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/GIT/Merlot/dialog-classification/counterfactuals.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m perturbations \u001b[39m=\u001b[39m pj\u001b[39m.\u001b[39;49mperturb(text)\n",
      "File \u001b[1;32mc:\\Users\\zyth0001\\Anaconda3\\envs\\dialog-classification\\lib\\site-packages\\polyjuice\\polyjuice_wrapper.py:247\u001b[0m, in \u001b[0;36mPolyjuice.perturb\u001b[1;34m(self, orig_sent, blanked_sent, is_complete_blank, ctrl_code, perplex_thred, num_perturbations, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mGenerating on these prompts:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts: logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 247\u001b[0m generated \u001b[39m=\u001b[39m generate_on_prompts(\n\u001b[0;32m    248\u001b[0m     generator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator, prompts\u001b[39m=\u001b[39mprompts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    249\u001b[0m merged \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(np\u001b[39m.\u001b[39mconcatenate(generated))\n\u001b[0;32m    251\u001b[0m validated_set \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\zyth0001\\Anaconda3\\envs\\dialog-classification\\lib\\site-packages\\polyjuice\\generations\\generator_helpers.py:72\u001b[0m, in \u001b[0;36mgenerate_on_prompts\u001b[1;34m(generator, prompts, temperature, num_beams, n, do_sample, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39ms:\u001b[39m\u001b[39m\"\u001b[39m,s)\n\u001b[0;32m     71\u001b[0m \u001b[39m#total_sequence = s[\"generated_text\"].split(PERETURB_TOK)[-1]\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m total_sequence \u001b[39m=\u001b[39m s[\u001b[39m\"\u001b[39;49m\u001b[39mgenerated_token_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(PERETURB_TOK)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     73\u001b[0m normalized, _ \u001b[39m=\u001b[39m remove_blanks(total_sequence)\n\u001b[0;32m     74\u001b[0m input_ctrl_code, normalized \u001b[39m=\u001b[39m split_ctrl_code(normalized)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from polyjuice import Polyjuice\n",
    "pj = Polyjuice(model_path=\"uw-hai/polyjuice\")\n",
    "text = \"It is great for kids.\"\n",
    "perturbations = pj.perturb(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import random\n",
    "\n",
    "model_path = \"uw-hai/polyjuice\"\n",
    "generator = pipeline(\"text-generation\", \n",
    "    model=AutoModelForCausalLM.from_pretrained(model_path), \n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_path),\n",
    "    framework=\"pt\", device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zyth0001\\Anaconda3\\envs\\dialog-classification\\lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't like painting with oil on a canvas.\n",
      "I like painting with oil on a canvas.\n",
      "I like painting with wood on canvas.\n",
      "I like painting with wood on a canvas.\n",
      "I like painting paintings with wood on a canvas.\n",
      "I like painting on a canvas.\n",
      "I prefer painting with oil on a canvas.\n",
      "I like painting with wood oil on a canvas.\n",
      "I like painting with wood instead of oil on a canvas.\n",
      "I like painting with oil on a rainy day.\n"
     ]
    }
   ],
   "source": [
    "text = \"I like painting with oil on a canvas.\"\n",
    "#text = \"What is the first law of thermodynamics?\"\n",
    "\n",
    "operations = ['negation', 'quantifier', 'shuffle', 'lexical', 'resemantic', 'insert', 'delete', 'restructure']\n",
    "blank_operations = [ 'shuffle', 'lexical', 'resemantic', 'insert', 'delete', 'restructure']\n",
    "\n",
    "generated_sentences = []\n",
    "\n",
    "for operation in operations:\n",
    "    prompt_text =  text + \" <|perturb|> [\"+ operation +\"]\"\n",
    "    generated_sentences.append(generator(prompt_text, num_beams=3, num_return_sequences=1))\n",
    "\n",
    "# todo randomly set [BLANK]\n",
    "text_parts = text.split()\n",
    "for operation in blank_operations:\n",
    "    replace_token = random.choice(text_parts)\n",
    "    randomized_blank = text.replace(replace_token, \"[BLANK]\")\n",
    "    prompt_text = text + \" <|perturb|> [\"+ operation +\"] \" + randomized_blank\n",
    "    generated_sentences.append(generator(prompt_text, num_beams=3, num_return_sequences=1))\n",
    "\n",
    "sentences = []\n",
    "for elements_list in generated_sentences:\n",
    "    for element in elements_list:\n",
    "        #print(element)\n",
    "        sentence = element['generated_text']\n",
    "        sentence_parts = sentence.split(' <|perturb|> ')\n",
    "        perturbation = sentence_parts[1]\n",
    "        for operation in operations:\n",
    "            perturbation = perturbation.replace(\"[\"+operation+\"]\",\"\")\n",
    "        perturbation_parts = perturbation.split(\" [SEP] \")\n",
    "        perturbed_sentence = perturbation_parts[0].replace(\"[BLANK]\", \"{}\")\n",
    "        answer_sentence = perturbation_parts[1]\n",
    "        answers = answer_sentence.split(\" [ANSWER] \")\n",
    "        sentence = perturbed_sentence.format(*answers)\n",
    "        sentence = sentence.replace(' EMPTY ', \" \").strip()\n",
    "        if sentence not in sentences:\n",
    "            sentences.append(sentence)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dialog-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c0e3b42618d32ec6361b866f028b0aedaa2f9f652f2692803f140ce18f5da83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
